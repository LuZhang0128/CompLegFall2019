##################################################
# read in the excel
# information about rename, replace, and split
##################################################
df_aa <- read.table("Former Committees' Names.xlsx")
############################
# detach and load packages
############################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "XML", "tidyr", "readxl"), pkgTest)
#######################
# parse HTML function
#######################
parse_HTML <- function(file) {
# get some information from the name of the file
info <- str_split(file, "\\/| - |\\.")
info <- unlist(info)
# read html
html <- read_html(file)
# select name
raw <- html %>%
html_nodes("h3") %>%
html_text()
# omit confounding names
clean <- raw[raw!="What do Select Committees do?"
& raw!= "Commons committee calendar"
& raw!= "Guide for witnesses"
& raw!= "Watch Parliament TV"
& raw!= "House of Lords Committee Bulletin"
& raw!= "Scrutiny uncovered"]
# return the dataframe
out <- data.frame(committee_type = info[3],
committee_name = clean)
return(out)
}
################################
# read in html
# parse and create raw dataset
################################
setwd('~/Documents/GitHub/CompLegFall2019/data/uk_lower/Committee')
# file names
files <- list.files(pattern="*.html", full.names=TRUE, recursive=FALSE)
# parse HTML
out <- alply(.data = files, .margins = 1, .fun = parse_HTML, .progress = "text", .inform = TRUE)
# stack data frames
df <- do.call("rbind", out)
##################################################
# read in the excel
# information about rename, replace, and split
##################################################
df_aa <- read_excel("Former Committees' Names.xlsx")
View(df_aa)
############################
# detach and load packages
############################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "XML", "tidyr"), pkgTest)
##########################
# set working directory
# import dataset
# create raw dataset
##########################
# set working directory
setwd('~/Documents/GitHub/CompLegFall2019/data/uk_lower/raw_characteristics/')
# read in dataset
files <- list.files(pattern="*.xml", full.names=TRUE, recursive=FALSE)
# to dataframe
committees <- xmlToDataFrame(files[1])
# alternative way
# xmldoc <- xmlParse(files[1])
# rootNode <- xmlRoot(xmldoc)
# rootNode[1]
# data <- xmlSApply(rootNode,function(x) xmlSApply(x, xmlValue))
# cd.catalog <- data.frame(t(data),row.names=NULL)
# constituencies <- xmlToDataFrame(files[2])
# experiences <- xmlToDataFrame(files[3])
# governmentPosts <- xmlToDataFrame(files[4])
# interests <- xmlToDataFrame(files[5])
# oppositionPosts <- xmlToDataFrame(files[6])
# parliamentaryPosts <- xmlToDataFrame(files[7])
# parties <- xmlToDataFrame(files[8])
# staff <- xmlToDataFrame(files[9])
##################################
# make the dataframe that we want
##################################
df <- committees
df$committees <- as.character(df$Committees)
df$committees[df$committees==""] <- "Temp"
df_a <- df %>%
mutate(full_name = DisplayAs) %>%
mutate(last_name = str_replace(ListAs,"(.*)(,\\s)(.*)","\\1")) %>%
mutate(first_name = str_replace(ListAs,"(.*)(,\\s)(.*)","\\3")) %>%
mutate(constituency_name = MemberFrom)
df_b <- df_a %>%
mutate(committees = gsub("False", "", committees)) %>%
mutate(committees = gsub("True", "", committees)) %>%
mutate(committees = strsplit(as.character(committees), "(?<=\\d{4}-\\d{2}-\\d{2}T00:00:00[A-Z])", perl = TRUE)) %>%
unnest(committees)
for (i in 1:nrow(df_b)){
if (str_sub(df_b$committees[i],-1,-1) == [A-Z]){
paste(str_sub(df_b$committees[i],-1,-1), df_b$committees[i+1], sep="")
}
}
if (str_sub(df_b$committees,-1,-1) == "[A-Z]"){
paste(str_sub(df_b$committees,-1,-1), df_b$committees, sep="")
}
View(df_b)
if (df_b$committees[i][-1] == "[A-Z]"){
paste(df_b$committees[i][-1], df_b$committees[i+1], sep="")
}
i=0
for(i in 1:nrow(df_b)){
if (df_b$committees[i][-1] == "[A-Z]"){
paste(df_b$committees[i][-1], df_b$committees[i+1], sep="")
}
}
df_b$committees[i][-1]
df_b$committees[1][-1]
df_b$committees[2][-1]
nrow(df_b)
for(i in 1:nrow(df_b)){
if (df_b$committees[i][-1] == "[A-Z]"){
paste(df_b$committees[i][-1], df_b$committees[i+1], sep="")
}
}
df_b$committees[1][-1]
as.character(df_b$committees)
df_b$committees <- as.character(df_b$committees)
if (df_b$committees[i][-1] == "[A-Z]"){
paste(df_b$committees[i][-1], df_b$committees[i+1], sep="")
}
df_b$committees[1][-1]
df_b$temp <- substring(df_b$committees, -1, -1)
df_b$committees[1][nchar()]
df_b$committees[1][nchar(x)]
df_b$committees[1][nchar(df_b$committees)]
df_b$temp <- substring(df_b$committees, nchar(df_b$committees), nchar(df_b$committees))
df_b <- df_a %>%
mutate(committees = gsub("False", "", committees)) %>%
mutate(committees = gsub("True", "", committees)) %>%
mutate(committees = strsplit(as.character(committees), "(?<=\\d{4}-\\d{2}-\\d{2}T00:00:00[A-Z])", perl = TRUE)) %>%
unnest(committees)
df_b$temp <- substring(df_b$committees, nchar(df_b$committees), nchar(df_b$committees))
for(i in 1:nrow(df_b)){
if (df_b$temp != 0){
paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
}
warnings()
if (df_b$temp[i] != 0){
paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
if (df_b$temp[i] != "0"){
paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
df_b$committees[i+1] <- paste(df_b$temp[i], df_b$committees[i+1], sep="")
for(i in 1:nrow(df_b)-1){
if (df_b$temp[i] != "0"){
df_b$committees[i+1] <- paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
}
if (df_b$temp[i] != 0){
df_b$committees[i+1] <- paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
if (df_b$temp[i] != 0){
df_b$committees[i+1] <- paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
as.character(df_b$temp)
for(i in 1:nrow(df_b)-1){
if (df_b$temp[i] != 0){
df_b$committees[i+1] <- paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
}
df_b$temp[1] != "0"
df_b$committees[2] <- paste(df_b$temp[1], df_b$committees[2], sep="")
df_b <- df_a %>%
mutate(committees = gsub("False", "", committees)) %>%
mutate(committees = gsub("True", "", committees)) %>%
mutate(committees = strsplit(as.character(committees), "(?<=\\d{4}-\\d{2}-\\d{2}T00:00:00[A-Z])", perl = TRUE)) %>%
unnest(committees)
df_b$temp <- substring(df_b$committees, nchar(df_b$committees), nchar(df_b$committees))
as.character(df_b$temp)
df_b$temp[5] != "0"
for(i in 1:nrow(df_b)-1){
if (df_b$temp[i] != "0"){
df_b$committees[i+1] <- paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
}
sum(is.null(df_b$temp)
sum(is.null(df_b$temp))
sum(is.null(df_b$temp))
nrow(df_b)-1
if (df_b$temp[i] != 0){
df_b$committees[i+1] <- paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
if (df_b$temp[i] != "0"){
df_b$committees[i+1] <- paste(df_b$temp[i], df_b$committees[i+1], sep="")
}
############################
# detach and load packages
############################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "XML", "tidyr", "readxl"), pkgTest)
#######################
# parse HTML function
#######################
parse_HTML <- function(file) {
# get some information from the name of the file
info <- str_split(file, "\\/| - |\\.")
info <- unlist(info)
# read html
html <- read_html(file)
# select name
raw <- html %>%
html_nodes("h3") %>%
html_text()
# omit confounding names
clean <- raw[raw!="What do Select Committees do?"
& raw!= "Commons committee calendar"
& raw!= "Guide for witnesses"
& raw!= "Watch Parliament TV"
& raw!= "House of Lords Committee Bulletin"
& raw!= "Scrutiny uncovered"]
# return the dataframe
out <- data.frame(committee_type = info[3],
committee_name = clean)
return(out)
}
################################
# read in html
# parse and create raw dataset
################################
setwd('~/Documents/GitHub/CompLegFall2019/data/uk_lower/Committee')
# file names
files <- list.files(pattern="*.html", full.names=TRUE, recursive=FALSE)
# parse HTML
out <- alply(.data = files, .margins = 1, .fun = parse_HTML, .progress = "text", .inform = TRUE)
# stack data frames
df <- do.call("rbind", out)
##################################################
# read in the excel
# information about rename, replace, and split
##################################################
df_aa <- read_excel("Former Committees' Names.xlsx")
#####################
# clean the dataset
#####################
# clean up committee type
df$committee_type[df$committee_type=="Former Commons Select Committees"] <- "House of Commons select committees"
df$committee_type[df$committee_type=="Former Lords Select Committees"] <- "House of Lords Select Committees"
df$committee_type[df$committee_type=="Former Joint Select Committees"] <- "Joint Select Committees"
df$committee_type[df$committee_type=="Former Other Committees"] <- "Other Committees"
# assign chamber number
df$chamber_number[df$committee_type=="House of Commons select committees"] <- 1
df$chamber_number[df$committee_type=="House of Lords Select Committees"] <- 2
df$chamber_number[df$committee_type=="Joint Select Committees"] <- 3
df$chamber_number[df$committee_type=="Other Committees"] <- 4
# committee number
df <- df[order(as.character(df$committee_name)),]
rownames(df) <- c()
df$committee_number <- rownames(df)
# observation number
df_a <- df[order(as.numeric(df$chamber_number), as.numeric(df$committee_number)),]
rownames(df_a) <- c()
df_a$observation_number <- rownames(df_a)
# path
df_a$chamber_path <- paste("/chamber-", df_a$chamber_number, sep="")
df_a$committee_path <- paste(df_a$chamber_path,"/committee-",df_a$committee_number,sep="")
df_a$observation_path <- paste(df_a$committee_path,"/observation-",df_a$observation_number,sep="")
uk_committees <- df_a %>%
select(observation_path,
chamber_path,
committee_path,
observation_number,
chamber_number,
committee_number,
committee_name,
committee_type)
#####################
# write csv
#####################
setwd('~/Documents/GitHub/CompLegFall2019/data/uk_lower/Output')
#write.csv(uk_committees, "uk_committees.csv")
View(uk_committees)
# to dataframe
committees <- xmlToDataFrame(files[1])
############################
# detach and load packages
############################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "XML", "tidyr"), pkgTest)
##########################
# set working directory
# import dataset
# create raw dataset
##########################
# set working directory
setwd('~/Documents/GitHub/CompLegFall2019/data/uk_lower/raw_characteristics/')
# read in dataset
files <- list.files(pattern="*.xml", full.names=TRUE, recursive=FALSE)
# to dataframe
committees <- xmlToDataFrame(files[1])
View(committees)
committees$Committees[1]
# these datasets come from http://data.parliament.uk/membersdataplatform/memberquery.aspx
# they include:
# (1) Member name and general info
# (2) Parties they've been apart of
# (3) Government posts they've held
# (4) Opposition posts they've held
# (5) Parliamentary posts they've held
# (6) Committees they've participated on
# (7) Constituencies they've served
#####################
# load libraries
# set wd
# clear global .envir
#####################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "lubridate"), pkgTest)
# working directoy
setwd("~/Documents/GitHub/CompLegFall2019/data/uk_lower/")
####################
# Download XML files
####################
# need to iterate over different criteria to download
# first, select that characteristics we're interested in
MPcharacteristics <- c("Committees"#, "OppositionPosts", "GovernmentPosts", "Constituencies",
# "Parties", "ParliamentaryPosts"
#, "Experiences", "Interests", "Staff"
)
# indicate the base URL to include all members from Commons
baseURL <- "http://data.parliament.uk/membersdataplatform/services/mnis/members/query/House=Commons|Membership=all/"
MPcharacteristics
# set url
url <- str_c(baseURL, MPcharacteristics[1], collapse = "")
url
# to dataframe
committees <- xmlToList(files[1])
############################
# detach and load packages
############################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "XML", "tidyr"), pkgTest)
##########################
# set working directory
# import dataset
# create raw dataset
##########################
# set working directory
setwd('~/Documents/GitHub/CompLegFall2019/data/uk_lower/raw_characteristics/')
# read in dataset
files <- list.files(pattern="*.xml", full.names=TRUE, recursive=FALSE)
# to dataframe
committees <- xmlToList(files[1])
View(committees)
# to dataframe
committees <- xmlToList(xmlParse(files[1]))
View(committees)
