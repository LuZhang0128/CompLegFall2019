# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "readxl"), pkgTest)
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
df <- read.csv("raw_canada_committee_membership.csv")
df_a <- read_excel("raw_canada_committees.xlsx")
df_b <- merge(x=df, y=df_a, by=c("committee_acronym","parliament_number","session_number"), all.x=TRUE)
df_b$ps <- paste(df_b$parliament_number,df_b$session_number, sep="_")
df_b$sd <- df_b %>%
group_by(ps) %>%
group_by(full_name) %>%
slice(which.min(start_date, date_change)) %>%
distinct()
df_b$sd <- df_b %>%
group_by(ps) %>%
group_by(full_name) %>%
slice(which.min(date_change)) %>%
distinct()
start_date $sd <- df_b %>%
group_by(ps) %>%
group_by(full_name) %>%
slice(which.min(date_change)) %>%
distinct()
start_date <- df_b %>%
group_by(ps) %>%
group_by(full_name) %>%
slice(which.min(date_change)) %>%
distinct()
end_date <- df_b %>%
group_by(ps) %>%
group_by(full_name) %>%
slice(which.max(date_change)) %>%
distinct()
View(end_date)
end_date <- df_b %>%
group_by(ps) %>%
group_by(full_name) %>%
slice(which.max(date_change)) %>%
distinct()
end_date
View(end_date)
end_date <- df_b %>%
group_by(ps, full_name) %>%
slice(which.max(date_change)) %>%
distinct()
start_date <- df_b %>%
group_by(ps, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
View(start_date)
#######################
# set working directory
# load data
# and load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "readxl"), pkgTest)
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
df <- read.csv("raw_canada_committee_membership.csv")
df_a <- read_excel("raw_canada_committees.xlsx")
df_b <- merge(x=df, y=df_a, by=c("committee_acronym","parliament_number","session_number"), all.x=TRUE)
df_b$ps <- paste(df_b$parliament_number,df_b$session_number, sep="_")
start_date <- df_b %>%
group_by(ps, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
end_date <- df_b %>%
group_by(ps, full_name) %>%
slice(which.max(date_change)) %>%
distinct()
View(end_date)
View(start_date)
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
df <- read.csv("raw_canada_committee_membership.csv")
df_a <- read_excel("raw_canada_committees.xlsx")
df_b <- merge(x=df, y=df_a, by=c("committee_acronym","parliament_number","session_number"), all.x=TRUE)
df_b$ps <- paste(df_b$parliament_number,df_b$session_number, sep="_")
df_c <- df_b %>%
group_by(ps, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
df_d <- df_b %>%
group_by(ps, full_name) %>%
slice(which.max(date_change)) %>%
distinct()
df_c$end_date = df_d$end_date
View(df_c)
df_c$end_date = df_d$end_date
#######################
# load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo"), pkgTest)
########################
# read in data useful
########################
# set working directory
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
df <- read.csv("canada_committees_date_change.csv")
###################################
# read in useful data in iteration
###################################
# change the date to the one in url
df$date_change <- gsub(",","",df$date_change)
df$dc <- as.Date(df$date_change, format="%B %d %Y")
x <- nrow(df)
# download through iteration
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees/Membership')
dc <- df$dc
acronym <- df$committee_acronym
pn <- df$parliament_number
sn <- df$session_number
number <- paste("/Members?parl=",pn,"&session=",sn,"&membershipOn=", sep="")
for(i in 1:x){
url <- paste("https://www.ourcommons.ca/Committees/en/", acronym[i], number[i], "#committeeMembersPanel", sep="")
file <- paste(acronym[i], "_", pn[i], "_", sn[i], "_", dc[i], ".html", sep="")
# download.file(url, file, quiet = TRUE)
}
#######################
# parse HTML function
#######################
parse_HTML <- function(file) {
# get some information from the name of the file
info <- str_split(file, "\\/|_|\\.")
info <- unlist(info)
# read html
html <- read_html(file)
# full_name, last_name, first_name, and title
raw <- html %>%
html_nodes(".title,.first-name") %>%
html_text()
# check
if(length(raw) == 0) {
return(NULL)
}
x <- as.numeric(which(raw=="Chair"))
y <- as.numeric(which(raw=="Vice-Chairs" | raw=="Vice-Chair"))
z <- as.numeric(which(raw=="Members"))
k <- as.numeric(length(raw))
if (is_empty(x)) {
x <- 0
}
if (is_empty(y)) {
y <- 0
}
if (is_empty(z)) {
z <- 0
}
if (is_empty(k)) {
k <- 0
}
title <- "Initiate"
title[c(x:(y-1))] <- "Chair"
title[c(y:(z-1))] <- "Co-chair"
title[c(z:k)] <- "Member"
# title <- "Initiate"
# if(x!=(y-1)) {
#   title[c(x:(y-1))] <- "Chair"
# }
# if(y!=(z-1)){
#   title[c(y:(z-1))] <- "Co-chair"
# }
# if(z!=k){
#   title[c(z:k)] <- "Member"
# }
first_name <- raw[-c(x,y,z)][c(TRUE,FALSE)]
title <- title[-c(x,y,z)][c(TRUE,FALSE)]
last_name <- html %>%
html_nodes(".last-name") %>%
html_text()
last_name <- last_name[c(TRUE,FALSE)]
full_name <- paste(first_name, last_name, sep=" ") %>%
unique()
# return the dataframe
out <- data.frame(committee_acronym = info[3],
parliament_number = info[4],
session_number = info[5],
date_change = info[6],
position = title,
first_name = first_name,
last_name = last_name,
full_name = full_name)
return(out)
}
#####################
# read in data
#####################
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees/Membership')
# file names
files <- list.files(pattern="*.html", full.names=TRUE, recursive=FALSE)
# parse XML
out <- alply(.data = files, .margins = 1, .fun = parse_HTML, .progress = "text", .inform = TRUE)
# stack data frames
df <- do.call("rbind", out)
raw_canada_committee_membership <- df
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
write.csv(raw_canada_committee_membership, "raw_canada_committee_membership.csv")
###########
# clean
###########
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
df <- read.csv("raw_canada_committee_membership.csv")
df_a <- read_excel("raw_canada_committees.xlsx")
df_b <- merge(x=df, y=df_a, by=c("committee_acronym","parliament_number","session_number"), all.x=TRUE)
df_b$ps <- paste(df_b$parliament_number,df_b$session_number, sep="_")
df_c <- df_b %>%
group_by(ps, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
df_d <- df_b %>%
group_by(ps, full_name) %>%
slice(which.max(date_change)) %>%
distinct()
df_c$end_date = df_d$end_date
df_e <- df_c %>%
select(committee_name,
committee_acronym,
parliament_number,
session_number,
position,
)
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
df <- read.csv("raw_canada_committee_membership.csv")
df_a <- read_excel("raw_canada_committees.xlsx")
df_b <- merge(x=df, y=df_a, by=c("committee_acronym","parliament_number","session_number"), all.x=TRUE)
df_b$ps <- paste(df_b$parliament_number,df_b$session_number, sep="_")
df_c <- df_b %>%
group_by(ps, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
df_d <- df_b %>%
group_by(ps, full_name) %>%
slice(which.max(date_change)) %>%
distinct()
df_c$end_date = df_d$end_date
df_e <- df_c %>%
select(committee_name,
committee_acronym,
parliament_number,
session_number,
position,
)
#######################
# load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "readxl"), pkgTest)
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
df <- read.csv("raw_canada_committee_membership.csv")
df_a <- read_excel("raw_canada_committees.xlsx")
df_b <- merge(x=df, y=df_a, by=c("committee_acronym","parliament_number","session_number"), all.x=TRUE)
df_b$ps <- paste(df_b$parliament_number,df_b$session_number, sep="_")
df_c <- df_b %>%
group_by(ps, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
df_d <- df_b %>%
group_by(ps, full_name) %>%
slice(which.max(date_change)) %>%
distinct()
df_c$end_date = df_d$end_date
df_e <- df_c %>%
select(committee_name,
committee_acronym,
parliament_number,
session_number,
position,
)
View(df_e)
View(df_d)
setwd('~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Committees')
df <- read.csv("raw_canada_committee_membership.csv")
df_a <- read_excel("raw_canada_committees.xlsx")
df_b <- merge(x=df, y=df_a, by=c("committee_acronym","parliament_number","session_number"), all.x=TRUE)
df_b$ps <- paste(df_b$parliament_number,df_b$session_number, sep="_")
df_c <- df_b %>%
group_by(ps, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
df_d <- df_b %>%
group_by(ps, full_name) %>%
slice(which.max(date_change)) %>%
distinct()
df_c$end_date = df_d$end_date
df_e <- df_c %>%
select(committee_name,
committee_acronym,
parliament_number,
full_name,
session_number,
position,
start_date,
end_date
)
df_c <- df_b %>%
group_by(parliament_number, session_number, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
df_c <- df_b %>%
group_by(parliament_number, session_number, full_name) %>%
slice(which.min(date_change)) %>%
distinct()
df_d <- df_b %>%
group_by(parliament_number, session_number, full_name) %>%
slice(which.max(date_change)) %>%
distinct()
df_c$end_date = df_d$end_date
df_e <- df_c %>%
select(committee_name,
committee_acronym,
parliament_number,
full_name,
session_number,
position,
start_date,
end_date
)
df_e <- df_c %>%
select(committee_name,
committee_acronym,
parliament_number,
full_name,
session_number,
position,
start_date,
end_date
) %>%
distinct()
canada_floor_speeches <- read.csv("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Examples/canada_floor_speeches.csv")
View(canada_floor_speeches)
#################
df <- read.csv("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Examples/canada_floor_speeches.csv")
View(canada_floor_speeches)
#######################
# load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "quanteda"), pkgTest)
#################
df <- read.csv("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Examples/canada_floor_speeches.csv")
df$paragrah_text
?quanteda
stopwords("en")
df$paragraph_path
df$paragraph_text
View(df$paragraph_text)
#######################
# load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "quanteda"), pkgTest)
#################
df <- read.csv("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Examples/canada_floor_speeches.csv")
df_a <- df$paragraph_text %>%
filter(!name %in% stopwords("en"))
View(df_a)
#######################
# load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "quanteda"), pkgTest)
#################
df <- read.csv("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Examples/canada_floor_speeches.csv")
df_a <- df$paragraph_text %>%
as.character() %>%
filter(!name %in% stopwords("en"))
View(df_a)
#######################
# load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo", "quanteda"), pkgTest)
#################
df <- read.csv("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Examples/canada_floor_speeches.csv")
df_a <- df$paragraph_text %>%
filter(!%in% stopwords("en"))
View(df_a)
df_a <- df$paragraph_text %>%
filter(! %in% stopwords("en"))
df$clean <- df$paragraph_text[!df$paragraph_text %in% stopwords("en")]
View(df)
tolower(df$clean)
View(df)
View(df$clean)
df$clean <- tolower(df$clean)
